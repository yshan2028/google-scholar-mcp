# ğŸš€ Google Scholar MCP Server - v2.0.0 å‘å¸ƒ

## ğŸ“¦ å‘å¸ƒå†…å®¹

### âœ¨ ä¸»è¦åŠŸèƒ½
- **Google Scholar API é›†æˆ** - æ”¯æŒè®ºæ–‡æœç´¢ã€ä½œè€…æŸ¥è¯¢ã€BibTeX æ¡ç›®è¡¥å…¨
- **å¤šæº API æ”¯æŒ** - ScrapingDog â†’ SerpAPI â†’ scholarlyï¼ˆä¸‰çº§é™çº§ï¼‰
- **å®Œæ•´æ•°æ®è¿”å›** - 25+ ä¸ªå­—æ®µï¼ŒåŒ…æ‹¬å®Œæ•´æ‘˜è¦ã€æ‰€æœ‰ PDF é“¾æ¥ã€å¼•ç”¨ä¿¡æ¯
- **BibTeX ç”Ÿæˆ** - æ”¯æŒ 18+ ä¸ªå­—æ®µçš„å®Œæ•´æ¡ç›®ç”Ÿæˆ
- **Docker éƒ¨ç½²** - æ”¯æŒæœ¬åœ°éƒ¨ç½²å’Œ Docker å®¹å™¨åŒ–

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ç‰¹æ€§

#### 1ï¸âƒ£ è®ºæ–‡æœç´¢ä¸æŸ¥è¯¢
- æŒ‰æ ‡é¢˜ã€DOIã€å…³é”®è¯ç²¾ç¡®æŸ¥è¯¢
- è¿”å›å®Œæ•´çš„è®ºæ–‡ä¿¡æ¯å’Œå…ƒæ•°æ®
- æ”¯æŒåˆ†é¡µç»“æœ

#### 2ï¸âƒ£ å®Œæ•´æ•°æ®ç»“æ„
```json
{
  "title": "è®ºæ–‡æ ‡é¢˜",
  "abstract": "å®Œæ•´æ‘˜è¦ï¼ˆä¸æˆªæ–­ï¼‰",
  "authors": {
    "display": "æ˜¾ç¤ºæ ¼å¼",
    "list": [{"name": "...", "profile_link": "...", "author_id": "..."}]
  },
  "publication": {"venue": "æœŸåˆŠ/ä¼šè®®", "year": "å¹´ä»½"},
  "links": {"paper": "...", "pdf": "...", "pdf_all": [...]},
  "citations": {"count": 1000, "total_text": "Cited by 1000", "link": "..."},
  "versions": {"total": "70", "link": "...", "cluster_id": "..."},
  "metadata": {"source": "ScrapingDog", "has_pdf": true}
}
```

#### 3ï¸âƒ£ BibTeX æ¡ç›®ç”Ÿæˆ
æ”¯æŒå­—æ®µï¼š
- `author`, `title`, `journal`/`booktitle`, `year`, `month`
- `volume`, `number`, `pages`, `publisher`
- `doi`, `url`, `abstract`, `note`
- `eprint`, `archivePrefix`, `primaryClass` (arXiv)

#### 4ï¸âƒ£ API ä¼˜å…ˆçº§
1. **ScrapingDog** - æœ€å¿«æœ€ç¨³å®šï¼ˆæ¨èï¼‰
2. **SerpAPI** - å¤‡é€‰æ–¹æ¡ˆ
3. **scholarly** - å…è´¹å¤‡ç”¨

---

## ğŸ“‹ é¡¹ç›®ç»“æ„

```
Google-Scholar-MCP-Server/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ google_scholar_mcp/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ __main__.py
â”‚       â””â”€â”€ server.py (æ ¸å¿ƒé€»è¾‘)
â”œâ”€â”€ Dockerfile          # Docker é•œåƒå®šä¹‰
â”œâ”€â”€ docker-compose.yml  # å®¹å™¨ç¼–æ’
â”œâ”€â”€ pyproject.toml      # é¡¹ç›®é…ç½® (uv)
â”œâ”€â”€ uv.lock             # ä¾èµ–é”å®š
â”œâ”€â”€ README.md           # ä½¿ç”¨æ–‡æ¡£
â”œâ”€â”€ EPHEMERAL_MODE.md   # ä¸´æ—¶å®¹å™¨è¯´æ˜
â””â”€â”€ test_*.py           # æµ‹è¯•è„šæœ¬
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ 1: æœ¬åœ°éƒ¨ç½² (æ¨èå¼€å‘)

```bash
# 1. é…ç½® API Keys
cp env.example .env
# ç¼–è¾‘ .env å¡«å…¥å®é™…çš„ API keys:
# SCRAPINGDOG_API_KEY=your_key
# SERP_API_KEY=your_key

# 2. å®‰è£…ä¾èµ–
pip install uv
uv venv
source .venv/bin/activate
uv sync

# 3. å¯åŠ¨æœåŠ¡
python -m google_scholar_mcp
```

### æ–¹å¼ 2: Docker éƒ¨ç½² (ç”Ÿäº§æ¨è)

```bash
# 1. é…ç½®ç¯å¢ƒå˜é‡
export SCRAPINGDOG_API_KEY="your_key"
export SERP_API_KEY="your_key"

# 2. å¯åŠ¨å®¹å™¨
docker-compose up -d

# 3. Claude Desktop é…ç½®
åœ¨ ~/.claude/config.json ä¸­ï¼š
{
  "mcpServers": {
    "google-scholar": {
      "command": "docker",
      "args": ["run", "--rm", "-i",
        "-e", "SCRAPINGDOG_API_KEY=your_key",
        "-e", "SERP_API_KEY=your_key",
        "google-scholar-mcp:latest"]
    }
  }
}
```

### æ–¹å¼ 3: ä¸´æ—¶å®¹å™¨ (ä¸€æ¬¡æ€§æŸ¥è¯¢)

```bash
docker-compose --profile ephemeral up
# æŸ¥è¯¢å®Œæˆåè‡ªåŠ¨é”€æ¯
```

---

## ğŸ”§ é…ç½®

### ç¯å¢ƒå˜é‡
```bash
SCRAPINGDOG_API_KEY     # ScrapingDog API å¯†é’¥ï¼ˆä¼˜å…ˆï¼‰
SERP_API_KEY            # SerpAPI å¯†é’¥ï¼ˆå¤‡é€‰ï¼‰
```

### è·å– API Keys
- **ScrapingDog**: https://www.scrapingdog.com/
- **SerpAPI**: https://serpapi.com/

---

## ğŸ“š ä½¿ç”¨ç¤ºä¾‹

### Claude Desktop ä¸­è°ƒç”¨

```python
# æŒ‰æ ‡é¢˜æœç´¢
search_paper_by_title("Attention Is All You Need")

# æŒ‰ä½œè€…æŸ¥è¯¢
search_author_profile("Geoffrey Hinton")

# è¡¥å…¨ BibTeX
get_citation_info("Your Paper Title")
```

### è¿”å›æ•°æ®ç¤ºä¾‹

```json
{
  "title": "Attention Is All You Need",
  "authors": "A Vaswani, N Shazeer, ...",
  "year": "2017",
  "venue": "NeurIPS",
  "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight P100 GPUs, a small fraction of the training costs of the best models from the literature. We can benefit from larger trained models by applying code-switching to our attention mechanism.",
  "bibtex": "@article{vaswani_2017,\n  author = {A Vaswani, N Shazeer, ...},\n  title = {Attention Is All You Need},\n  journal = {Advances in neural information processing systems},\n  year = {2017},\n  url = {...},\n  abstract = {The dominant sequence...\n}\n"
}
```

---

## ğŸ” ä¸»è¦æ”¹è¿›ï¼ˆvs v1.0ï¼‰

| åŠŸèƒ½ | v1.0 | v2.0 |
|------|------|------|
| è¿”å›å­—æ®µ | ~8 ä¸ª | **25+ ä¸ª** âœ“ |
| æ‘˜è¦æˆªæ–­ | æ˜¯ | **å¦** âœ“ |
| BibTeX å­—æ®µ | ~10 ä¸ª | **18+ ä¸ª** âœ“ |
| ä½œè€…ä¿¡æ¯ | ä»…æ˜¾ç¤º | **å®Œæ•´åˆ—è¡¨** âœ“ |
| PDF é“¾æ¥ | ä»…é¦–ä¸ª | **å…¨éƒ¨** âœ“ |
| DOI æ”¯æŒ | æ—  | **æœ‰** âœ“ |
| eprint æ”¯æŒ | æ—  | **æœ‰** âœ“ |
| ä¾èµ–ç®¡ç† | pip | **uv** âœ“ |
| å¤šæº API | SerpAPI | **ä¸‰çº§é™çº§** âœ“ |

---

## ğŸ“– æ–‡æ¡£

- **README.md** - å®Œæ•´ä½¿ç”¨æŒ‡å—å’Œ API æ–‡æ¡£
- **EPHEMERAL_MODE.md** - ä¸´æ—¶å®¹å™¨éƒ¨ç½²è¯´æ˜
- **AUTO_CLEANUP_GUIDE.md** - å®¹å™¨æ¸…ç†æŒ‡å—

---

## ğŸ› å·²çŸ¥é—®é¢˜ & è§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1: scholarly è§¦å‘éªŒè¯ç 
**è§£å†³**: é»˜è®¤ä¼˜å…ˆä½¿ç”¨ ScrapingDogï¼Œscholarly ä½œä¸ºå¤‡ç”¨å…è´¹æ–¹æ¡ˆ

### é—®é¢˜ 2: Docker å®¹å™¨æœªè‡ªåŠ¨é”€æ¯
**è§£å†³**: ä½¿ç”¨ `--profile ephemeral` æˆ– `docker run --rm` å¯åŠ¨

### é—®é¢˜ 3: API è¿”å›ç»“æœä¸ºç©º
**è§£å†³**: æ£€æŸ¥ API å¯†é’¥æ˜¯å¦æ­£ç¡®ï¼Œæˆ–åˆ‡æ¢åˆ°å…¶ä»– API

---

## ğŸ” å®‰å…¨æ€§

- âœ… API å¯†é’¥å­˜å‚¨åœ¨ `.env` æ–‡ä»¶ï¼ˆGit å¿½ç•¥ï¼‰
- âœ… Docker æ”¯æŒä»ç¯å¢ƒå˜é‡ä¼ å…¥å¯†é’¥
- âœ… ä¸åœ¨ä»£ç ä¸­ç¡¬ç¼–ç å¯†é’¥
- âœ… `.dockerignore` æ’é™¤æ•æ„Ÿæ–‡ä»¶

---

## ğŸ“ æ›´æ–°æ—¥å¿—

### v2.0.0 (2025-10-23)
- âœ¨ å®Œæ•´æ•°æ®ç»“æ„è®¾è®¡ï¼ˆ25+ å­—æ®µï¼‰
- âœ¨ å®Œæ•´æ‘˜è¦è¿”å›ï¼ˆä¸æˆªæ–­ï¼‰
- âœ¨ å¢å¼º BibTeX ç”Ÿæˆï¼ˆ18+ å­—æ®µï¼‰
- ğŸ”§ è¿ç§»åˆ° `uv` åŒ…ç®¡ç†
- ğŸ³ æ”¹è¿› Docker éƒ¨ç½²æµç¨‹
- ğŸ“š å®Œå–„æ–‡æ¡£å’Œç¤ºä¾‹

---

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ ScrapingDogã€SerpAPI å’Œ scholarly ç¤¾åŒºçš„æ”¯æŒï¼

---

## ğŸ“„ è®¸å¯è¯

MIT License

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ PR å’Œ Issueï¼

---

**å‡†å¤‡å¥½å‘å¸ƒäº†å—ï¼ŸğŸš€**

